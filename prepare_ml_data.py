import json
import pandas as pd
import random
from sklearn.model_selection import train_test_split
import numpy as np

def combine_and_prepare_data():
    print("=" * 60)
    print("           VERÄ°LERÄ° BÄ°RLEÅžTÄ°RME VE ML HAZIRLIÄžI")
    print("=" * 60)
    
    # 1. TemizlenmiÅŸ verileri yÃ¼kle
    print("\nðŸ“¥ VERÄ°LER YÃœKLENÄ°YOR...")
    with open("clean_human.json", "r", encoding="utf-8") as f:
        human_data = json.load(f)
    
    with open("clean_ai.json", "r", encoding="utf-8") as f:
        ai_data = json.load(f)
    
    print(f"âœ“ Human verileri: {len(human_data)} Ã¶rnek")
    print(f"âœ“ AI verileri: {len(ai_data)} Ã¶rnek")
    
    # 2. Human verilerini hazÄ±rla (label: 0 = Human)
    print("\nðŸ§‘ HUMAN VERÄ°LERÄ° HAZIRLANIYOR...")
    human_samples = []
    for i, item in enumerate(human_data):
        human_samples.append({
            "text": item["summary"],
            "label": 0,  # 0 = Human
            "source": "arxiv",
            "title": item["title"][:100]  # BaÅŸlÄ±k kÄ±smÄ±nÄ± sakla (opsiyonel)
        })
    
    # 3. AI verilerini hazÄ±rla (label: 1 = AI)
    print("ðŸ¤– AI VERÄ°LERÄ° HAZIRLANIYOR...")
    ai_samples = []
    for i, item in enumerate(ai_data):
        # Sadece AI tarafÄ±ndan Ã¼retilen Ã¶zetleri kullan
        ai_samples.append({
            "text": item["ai_summary"],
            "label": 1,  # 1 = AI
            "source": "ai_generated",
            "title": item["title"][:100]
        })
    
    # 4. EK OPTÄ°YON: AI dataset'inden HUMAN Ã¶zetlerini de kullanabiliriz
    # (Daha fazla human verisi iÃ§in - opsiyonel)
    """
    print("âž• AI DOSYASINDAN HUMAN Ã–ZETLERÄ° EKLENÄ°YOR...")
    extra_human_samples = []
    for i, item in enumerate(ai_data):
        extra_human_samples.append({
            "text": item["human_summary"],
            "label": 0,  # Bu da human
            "source": "human_from_ai_dataset",
            "title": item["title"][:100]
        })
    
    human_samples.extend(extra_human_samples)
    print(f"  Eklenen human Ã¶rnek: {len(extra_human_samples)}")
    """
    
    # 5. TÃ¼m verileri birleÅŸtir
    print("\nðŸ”„ VERÄ°LER BÄ°RLEÅžTÄ°RÄ°LÄ°YOR...")
    all_samples = human_samples + ai_samples
    random.seed(42)  # Tekrarlanabilirlik iÃ§in
    random.shuffle(all_samples)
    
    # 6. DataFrame oluÅŸtur
    df = pd.DataFrame(all_samples)
    
    print(f"\nðŸ“Š TOPLAM VERÄ° SETÄ°:")
    print(f"  Toplam Ã¶rnek sayÄ±sÄ±: {len(df)}")
    
    # 7. Etiket daÄŸÄ±lÄ±mÄ±
    print("\nðŸŽ¯ ETÄ°KET DAÄžILIMI:")
    label_counts = df["label"].value_counts().sort_index()
    for label, count in label_counts.items():
        label_name = "Human" if label == 0 else "AI"
        percentage = (count / len(df)) * 100
        print(f"  {label_name} ({label}): {count} Ã¶rnek (%{percentage:.1f})")
    
    # 8. Metin uzunluklarÄ± analizi
    print("\nðŸ“ METÄ°N UZUNLUKLARI ANALÄ°ZÄ°:")
    df["text_length"] = df["text"].apply(len)
    
    print("\n  TÃœM VERÄ°LER:")
    print(f"    Ortalama: {df['text_length'].mean():.0f} karakter")
    print(f"    Minimum: {df['text_length'].min():.0f} karakter")
    print(f"    Maksimum: {df['text_length'].max():.0f} karakter")
    print(f"    Standart Sapma: {df['text_length'].std():.0f} karakter")
    
    print("\n  HUMAN METÄ°NLERÄ°:")
    human_df = df[df["label"] == 0]
    print(f"    Ortalama: {human_df['text_length'].mean():.0f} karakter")
    print(f"    Min-Max: {human_df['text_length'].min():.0f} - {human_df['text_length'].max():.0f}")
    
    print("\n  AI METÄ°NLERÄ°:")
    ai_df = df[df["label"] == 1]
    print(f"    Ortalama: {ai_df['text_length'].mean():.0f} karakter")
    print(f"    Min-Max: {ai_df['text_length'].min():.0f} - {ai_df['text_length'].max():.0f}")
    
    # 9. Train-Test Split (%80-%20)
    print("\nâœ‚ï¸  TRAIN-TEST AYIRMA (%80 Train, %20 Test)...")
    X = df["text"]
    y = df["label"]
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, 
        test_size=0.2, 
        random_state=42, 
        stratify=y  # SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± koru
    )
    
    print(f"  EÄŸitim seti: {len(X_train)} Ã¶rnek")
    print(f"  Test seti: {len(X_test)} Ã¶rnek")
    
    # 10. CSV olarak kaydet
    print("\nðŸ’¾ DOSYALAR KAYDEDÄ°LÄ°YOR...")
    
    # Tam dataset
    df.to_csv("full_dataset.csv", index=False, encoding="utf-8")
    
    # Train ve test setleri
    train_df = pd.DataFrame({"text": X_train, "label": y_train})
    test_df = pd.DataFrame({"text": X_test, "label": y_test})
    
    train_df.to_csv("train_data.csv", index=False, encoding="utf-8")
    test_df.to_csv("test_data.csv", index=False, encoding="utf-8")
    
    print("âœ“ full_dataset.csv - TÃ¼m veriler")
    print("âœ“ train_data.csv - EÄŸitim verileri")
    print("âœ“ test_data.csv - Test verileri")
    
    # 11. Ã–rnekler gÃ¶ster
    print("\nðŸ‘ï¸  Ã–RNEK VERÄ°LER (EÄŸitim setinden 2 Ã¶rnek):")
    for i in range(min(2, len(train_df))):
        label = train_df.iloc[i]["label"]
        label_name = "Human" if label == 0 else "AI"
        text_preview = train_df.iloc[i]["text"][:200] + "..." if len(train_df.iloc[i]["text"]) > 200 else train_df.iloc[i]["text"]
        print(f"\n  [{i+1}] {label_name} ({label}):")
        print(f"     {text_preview}")
    
    # 12. Dataset istatistikleri dosyasÄ±
    print("\nðŸ“ˆ Ä°STATÄ°STÄ°KLER DOSYASI OLUÅžTURULUYOR...")
    stats = {
        "total_samples": len(df),
        "human_samples": len(df[df["label"] == 0]),
        "ai_samples": len(df[df["label"] == 1]),
        "train_samples": len(train_df),
        "test_samples": len(test_df),
        "avg_text_length": float(df["text_length"].mean()),
        "min_text_length": int(df["text_length"].min()),
        "max_text_length": int(df["text_length"].max()),
        "human_avg_length": float(human_df["text_length"].mean()),
        "ai_avg_length": float(ai_df["text_length"].mean())
    }
    
    with open("dataset_stats.json", "w", encoding="utf-8") as f:
        json.dump(stats, f, indent=2, ensure_ascii=False)
    
    print("âœ“ dataset_stats.json - Ä°statistikler kaydedildi")
    
    print("\n" + "=" * 60)
    print("âœ… VERÄ° HAZIRLAMA BAÅžARIYLA TAMAMLANDI!")
    print("=" * 60)
    print("\nðŸŽ¯ BÄ°R SONRAKÄ° ADIM: 3 ML MODELÄ° EÄžÄ°TÄ°MÄ°")
    print("\nOluÅŸturulan dosyalar:")
    print("  - full_dataset.csv    : TÃ¼m veri seti")
    print("  - train_data.csv      : EÄŸitim iÃ§in")
    print("  - test_data.csv       : Test iÃ§in")
    print("  - dataset_stats.json  : Ä°statistikler")
    print("\nToplam Ã¶rnek sayÄ±sÄ±:", len(df))
    print("=" * 60)

if __name__ == "__main__":
    combine_and_prepare_data()